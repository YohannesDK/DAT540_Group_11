{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Solar Power Generation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This data has been gathered at two solar power plants in India over a 34 day period. It has two pairs of files - each pair has one power generation dataset and one sensor readings dataset. The power generation datasets are gathered at the inverter level - each inverter has multiple lines of solar panels attached to it. The sensor data is gathered at a plant level - single array of sensors optimally placed at the plant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we assume data files are in the same directory as the notebook.\n",
    "The data can be accessed at <https://www.kaggle.com/anikannal/solar-power-generation-data/download>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_1_gen = pd.read_csv(\"Plant_1_Generation_data.csv\")\n",
    "plant_2_gen = pd.read_csv(\"Plant_2_Generation_data.csv\")\n",
    "plant_1_wea = pd.read_csv(\"Plant_1_Weather_Sensor_data.csv\")\n",
    "plant_2_wea = pd.read_csv(\"Plant_2_Weather_Sensor_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check columns for missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Plant 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant1_wea = plant_1_wea.isnull().sum()\n",
    "print(plant1_wea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both weather and generation data has no null values, however this is time series data so what if there are dicontinuity in the time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gen1 = plant_1_gen.copy()\n",
    "temp_gen1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant2_info = plant_2_gen.isnull().sum()\n",
    "print(plant2_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant2_wea = plant_2_wea.isnull().sum()\n",
    "print(plant2_wea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant1_info = plant_1_gen.isnull().sum()\n",
    "print(plant1_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many sensors are at each plant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Plant 1 has\",plant_1_gen['SOURCE_KEY'].nunique(),\"sensors\")\n",
    "print(\"Plant 2 has\",plant_2_gen['SOURCE_KEY'].nunique(),\"sensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for 34 days and continuous dates\n",
    "numb_daws = pd.to_datetime(plant_1_gen['DATE_TIME']).dt.date.unique()\n",
    "\n",
    "plant_1_gen['DATE_TIME'] = pd.to_datetime(plant_1_gen['DATE_TIME'])\n",
    "\n",
    "data = plant_1_gen.groupby(['SOURCE_KEY']).apply(lambda x: x.sort_values(by=['DATE_TIME'], ascending=True))\n",
    "\n",
    "time_gaps = pd.DataFrame(data.DATE_TIME.iloc[1:].diff())\n",
    "non_continuous_dates = time_gaps.loc[(time_gaps.DATE_TIME.dt.seconds > 15*60) | (time_gaps.DATE_TIME.dt.seconds < -15*60)]\n",
    "non_continuous_dates.index.set_names([\"SOURCE_KEY\", \"Index\"], inplace=True)\n",
    "\n",
    "# non_continuous_dates.index.get_level_values(1)\n",
    "\n",
    "# plot the non-continuous dates to visualize time gaps. Use the multiindex to identify the sensors and the index of the time gaps\n",
    "\n",
    "# fill NaT values with 15 min timedelta, in non_continuous_dates\n",
    "non_continuous_dates.fillna(pd.Timedelta(15*60, unit='s'), inplace=True)\n",
    "\n",
    "time_gaps.plot(x='DATE_TIME', y='DATE_TIME', kind='scatter')\n",
    "non_continuous_dates.plot(x='DATE_TIME', y='DATE_TIME', kind='scatter')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some inverters have more data points then the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverterids\n",
    "print(\"Plant 1 statistics \\n\", plant_1_gen.SOURCE_KEY.value_counts())\n",
    "print(\"Plant 2 statistics \\n\", plant_2_gen.SOURCE_KEY.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Convert datetime column to datetime format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plant 1 weather data\n",
    "plant_1_wea['DATE_TIME'] = pd.to_datetime(plant_1_wea['DATE_TIME']) \n",
    "plant_1_wea['TIME'] = plant_1_wea['DATE_TIME'].dt.time \n",
    "#convert datetime column to just date\n",
    "plant_1_wea['DATE'] = pd.to_datetime(plant_1_wea['DATE_TIME'].dt.date)\n",
    "print(plant_1_wea['DATE'])\n",
    "\n",
    "#Plant 2 weather data\n",
    "plant_2_wea['DATE_TIME'] = pd.to_datetime(plant_2_wea['DATE_TIME']) \n",
    "plant_2_wea['TIME'] = plant_2_wea['DATE_TIME'].dt.time \n",
    "#convert datetime column to just date\n",
    "plant_2_wea['DATE'] = pd.to_datetime(plant_2_wea['DATE_TIME'].dt.date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analysis of weather dataset for both the plants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing both plants\n",
    "# Daily Irradiation\n",
    "ambient_compare = sns.lineplot(x='DATE', y='IRRADIATION', data=plant_1_wea, err_style='band', label='Plant 1')\n",
    "sns.lineplot(x='DATE', y='IRRADIATION', data=plant_2_wea, err_style='band', label='Plant 2', ax=ambient_compare)\n",
    "plt.ylabel('Irradiation')\n",
    "plt.xlabel('Date')\n",
    "plt.title('Daily Solar Irradiation for Both Plants')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# The mean of solar Irradiation for both plants are similar\n",
    "mean_irradiationplant1 = plant_1_wea['IRRADIATION'].mean()\n",
    "print('Mean of solar irradition from Plant1', mean_irradiationplant1)\n",
    "mean_irradiationplant2 =  plant_2_wea['IRRADIATION'].mean()\n",
    "print('Mean of solar irradition from Plant2', mean_irradiationplant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Module Temperature\n",
    "modtemp_compare = sns.lineplot(x='DATE', y='MODULE_TEMPERATURE', data=plant_1_wea, err_style='band', label='Plant 1')\n",
    "sns.lineplot(x='DATE', y='MODULE_TEMPERATURE', data=plant_2_wea, err_style='band', label='Plant 2', ax=modtemp_compare)\n",
    "plt.ylabel('Module Temperature')\n",
    "plt.xlabel('Date')\n",
    "plt.title('Daily Module Temperature for Both Plants')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# The mean of Module Temperature for both plants (Plant 1 is lower then Plant 2)\n",
    "mean_moduletempplant1 = plant_1_wea['MODULE_TEMPERATURE'].mean()\n",
    "print('Mean of Module Temperature from Plant1', mean_moduletempplant1)\n",
    "mean_moduletempplant2 =  plant_2_wea['MODULE_TEMPERATURE'].mean()\n",
    "print('Mean of Module Temperature from Plant2', mean_moduletempplant2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambtemp_compare = sns.lineplot(x='DATE', y='AMBIENT_TEMPERATURE', data=plant_1_wea, err_style='band', label='Plant 1')\n",
    "sns.lineplot(x='DATE', y='AMBIENT_TEMPERATURE', data=plant_2_wea, err_style='band', label='Plant 2', ax=ambtemp_compare)\n",
    "plt.ylabel('Ambient Temperature')\n",
    "plt.xlabel('Date')\n",
    "plt.title('Daily Ambient Temperature for Both Plants')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# The mean of Ambient Temperature for both plants (Plant 1 is lower then Plant 2)\n",
    "mean_ambienttempplant1 = plant_1_wea['AMBIENT_TEMPERATURE'].mean()\n",
    "print('Mean of Ambient Temperature from Plant1', mean_ambienttempplant1)\n",
    "mean_ambienttempplant2 =  plant_2_wea['AMBIENT_TEMPERATURE'].mean()\n",
    "print('Mean of Ambient Temperature from Plant2', mean_ambienttempplant2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "1. The mean solar irradiation values for both plants are similar.\n",
    "2. The mean module temperature of Plant 1 is  lower than Plant 2 most of the time.\n",
    "3. The mean ambient temperature of Plant 1 is much lower than Plant 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform and merge the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop unwanted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather1 = plant_1_wea.drop(['PLANT_ID', 'SOURCE_KEY'], axis=1)\n",
    "df_plant1 = plant_1_gen.drop(['PLANT_ID'], axis=1)\n",
    "df_weather2 = plant_2_wea.drop(['PLANT_ID', 'SOURCE_KEY'], axis=1)\n",
    "df_plant2 = plant_2_gen.drop(['PLANT_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plant1[\"Human_key\"] = df_plant1[\"SOURCE_KEY\"].map({val: f\"S{i:02d}\" for i, val in enumerate(df_plant1[\"SOURCE_KEY\"].unique())})\n",
    "df_plant1.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatedattime\n",
    "df_plant1['DATE_TIME']= pd.to_datetime(df_plant1['DATE_TIME'],format='%d-%m-%Y %H:%M')\n",
    "df_weather1['DATE_TIME']= pd.to_datetime(df_weather1['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')\n",
    "#df_plant1.head()\n",
    "df_plant2['DATE_TIME']= pd.to_datetime(df_plant2['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')\n",
    "df_weather2['DATE_TIME']= pd.to_datetime(df_weather2['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plant_weather1 = df_plant1.merge(df_weather1, left_on='DATE_TIME', right_on='DATE_TIME')\n",
    "df_plant_weather2 = df_plant2.merge(df_weather2, left_on='DATE_TIME', right_on='DATE_TIME')\n",
    "\n",
    "print(df_plant_weather1.head())\n",
    "print(df_plant_weather2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Correlation Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Observations:\n",
    "1. High correlation between DC Power and AC power generation\n",
    "2. High correlation between DC Power and IRRADIATION\n",
    "3. Strong correlation between DC Power, AC Power and Module Temperature and Ambient Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_plant_weather1.corr()\n",
    "\n",
    "corr_matrix[\"DC_POWER\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"DC_POWER\", \"AC_POWER\", \"IRRADIATION\",\n",
    "              \"MODULE_TEMPERATURE\",\"AMBIENT_TEMPERATURE\"]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter_plot = scatter_matrix(df_plant_weather1[attributes], figsize=(15, 15))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "fig_corr = sns.heatmap(corr_matrix,cmap=\"YlGnBu\", annot=True) # TODO - subplot + margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of DC power generated from each Source Keys.**\n",
    "1. TheDistribution DC power generation plot shows multiple occasion where power generated was zero during daytime.\n",
    "2.  plot of solar irradiation exhibits that the solar radiation never dropped to a lower value at day time. \n",
    "3. Analysis shows some inverters received no DC power even through there was enough sunlight\n",
    "4. It could be concluded that the DC power generated and solar irradiation has a linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Stacked Visualization of Power Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC power generated from each source keys\n",
    "sources=df_plant_weather1.copy()\n",
    "sources['time']=sources['DATE_TIME'].dt.time\n",
    "sources.set_index('time').groupby('SOURCE_KEY')['DC_POWER'].plot(style='o',legend=True,figsize=(20,10))\n",
    "plt.title('DC Power generated for all interverters(source_keys)',size=17)\n",
    "plt.ylabel('DC POWER ( kW )',color='purple',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverters with lower performace then rest \"1BY6WEcLGh8j5v7\", \"bvBOhCH3iADSZry\"\n",
    "SOURCE = df_plant_weather1.groupby('SOURCE_KEY').agg({'DC_POWER': ['mean', 'min', 'max','median']})['DC_POWER']\n",
    "SOURCE[\"SOURCE_KEY\"] = SOURCE.index\n",
    "mean = SOURCE['mean'].mean()\n",
    "SOURCE[\"mean_new\"] = SOURCE['mean'] - mean\n",
    "print(SOURCE.head())\n",
    "\n",
    "SOURCE.plot(x=\"SOURCE_KEY\", y=\"mean_new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solar power plants generate a vast amount of data which can be used to determine how a plant is performing and what is impacting its performance. Taking this a step further, a plant’s performance can be optimized by leveraging advanced analytics. Advanced analytics includes formulating statistical matrices, implementing actionable performance alarms, and conducting artificial intelligent models to predict future performance. A relatively accurate energy prediction can be calculated by incorporating weather forecasts, a plant’s historical performance\n",
    "This method requires substantial computing power and considerable time to develop accurate predictions. To illustrate this, this project will attempt to analyze power generation data in tandem with weather data to predict near-future (days) performance with data gathered from two solar power plants in India over a 34-day period.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features of interest / Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of power generation using different ML techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an appropriate ML model based on the dataset and your problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(y_test, y_pred):\n",
    "    R2_train = r2_score(y_test, y_pred)\n",
    "    mse_train = mean_squared_error(y1_train, Y1_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    return(R2_train, mse_train, rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "From the data analysis and corerelation analsysis it was inferred that there is a linear relation between the DC power generated andthe solar irradiation. This relation can be modeled using a simple linear relationship as below,\n",
    "𝑃(𝑡) = 𝑎 + 𝑏 . 𝐸(𝑡) where p(t) denotes the power generated and the E(t) denotes the solar irradiation. So we will run a linear regression model on our datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Linear Regression for Plant 1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=df_plant_weather1[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE']] # Features \n",
    "y1=df_plant_weather1['DC_POWER'] # independent var / predictor\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=1)\n",
    "\n",
    "print(\"Shape of each Dataset : \")\n",
    "print(\"X Train Shape = \",X1_train.shape)\n",
    "print(\"Y Train Shape = \",y1_train.shape)\n",
    "print(\"X Test Shape  = \",X1_test.shape)\n",
    "print(\"Y Test Shape  = \",y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X1_train, y1_train)\n",
    "lm.intercept_, lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Plant 1 linear regression cofficients are:', X1.columns, lm.coef_ )\n",
    "print('Plant 1 intercept', lm.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction_plant1 = lm.predict(X1_test)\n",
    "Prediction_plant1\n",
    "Y1_pred_train = lm.predict(X1_train)\n",
    "Y1_pred_test = lm.predict(X1_test)\n",
    "\n",
    "print ('Prediction Train dataset', Y1_pred_train)\n",
    "print ('Prediction Train dataset', Y1_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Solar Output Values vs Predicted Values for Plant 1 using Linear Regression (This also includes faulty days dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y1_test, Y1_pred_test,color=\"b\", label=\"Predicted Output\")\n",
    "plt.legend()\n",
    "plt.title('Actual Solar Output Values vs Predicted Values for Plant 1')\n",
    "plt.xlabel('Predicted Output')\n",
    "plt.ylabel('Actual Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation for Linear Regression Model 1 using RMSE( Plant1 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Evaluation for Linear Regression Model 1 using RMSE( Plant1)\")\n",
    "print(\"\")\n",
    "RMSE_train_1 = np.sqrt( metrics.mean_squared_error(y1_train, Y1_pred_train))\n",
    "RMSE_test_1 = np.sqrt(metrics.mean_squared_error(y1_test, Y1_pred_test))\n",
    "MAE1 = metrics.mean_absolute_error(y1_test, Y1_pred_test)\n",
    "MSE1 = metrics.mean_squared_error(y1_test, Y1_pred_test)\n",
    "RMSE1 = np.sqrt(metrics.mean_squared_error(y1_test, Y1_pred_test))\n",
    "print('RMSE for training set = {}'.format(round(RMSE_train_1,2)))\n",
    "print('RMSE for test set = {}'.format(round(RMSE_test_1,2)))\n",
    "print('MAE: ', MAE1)\n",
    "print('MSE: ',MSE1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : Linear Regression for Plant 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X12=df_plant_weather2[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE','IRRADIATION']] # Features \n",
    "y12=df_plant_weather2['DC_POWER'] # independent var / predictor\n",
    "\n",
    "X12_train, X12_test, y12_train, y12_test = train_test_split(X12, y12, test_size=0.20, random_state=1)\n",
    "\n",
    "print(\"Shape of each Dataset : \")\n",
    "print(\"X Train Shape = \",X12_train.shape)\n",
    "print(\"Y Train Shape = \",y12_train.shape)\n",
    "print(\"X Test Shape  = \",X12_test.shape)\n",
    "print(\"Y Test Shape  = \",y12_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit on training data for Plant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lm.fit(X12_train, y12_train)\n",
    "lm.intercept_, lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction_plant2 = lm.predict(X12_test)\n",
    "Prediction_plant2\n",
    "Y12_pred_train = lm.predict(X12_train)\n",
    "Y12_pred_test = lm.predict(X12_test)\n",
    "\n",
    "\n",
    "\n",
    "print ('Prediction Train dataset', Y12_pred_train)\n",
    "print ('Prediction Train dataset', Y12_pred_test)\n",
    "\n",
    "scoring(y12_test, Prediction_plant2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Solar Output Values vs Predicted Values for Plant 2 using Linear Regression (This also includes faulty days dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y12_test, Y12_pred_test, color=\"r\", label=\"Predicted Output for test\")\n",
    "plt.scatter(y12_train, Y12_pred_train, color=\"b\", label=\"Predicted Output for train\")\n",
    "plt.legend()\n",
    "plt.title('Actual Solar Output Values vs Predicted Values for Plant 2')\n",
    "plt.xlabel('Predicted Output')\n",
    "plt.ylabel('Actual Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score for Plant 2 using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_12 = lm.score(X12_train, y12_train)\n",
    "test_score_12 = lm.score(X12_test, y12_test)\n",
    "\n",
    "print(\"Model 1 Plant 2 accuracy score: \")\n",
    "print(\"\")\n",
    "print(\"Train Score = \",round(train_score_12*100,0),\"%\")\n",
    "print(\"Test Score  = \",round(test_score_12*100,0), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest for Plant2 dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns that will be used to create train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = df_plant_weather2\n",
    "model_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = model_2[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']] # Features\n",
    "y2 = model_2['DC_POWER'] # Target\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test=train_test_split(X2, y2, test_size=0.20, random_state=1, shuffle=False) \n",
    "\n",
    "print(\"Shape of each New Dataset : \")\n",
    "print(\"X Train Shape = \",X2_train.shape)\n",
    "print(\"Y Train Shape = \",y2_train.shape)\n",
    "print(\"X Test Shape  = \",X2_test.shape)\n",
    "print(\"Y Test Shape  = \",y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF = RandomForestRegressor()\n",
    "RF.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred_train = RF.predict(X2_train)\n",
    "y2_pred_test = RF.predict(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Evaluation for Random Forest Model 2 using RMSE\")\n",
    "\n",
    "RMSE_train_2 = np.sqrt( metrics.mean_squared_error(y2_train, y2_pred_train))\n",
    "RMSE_test_2 = np.sqrt(metrics.mean_squared_error(y2_test, y2_pred_test))\n",
    "MSE_train_2 = ( metrics.mean_squared_error(y2_train, y2_pred_train))\n",
    "print('RMSE for training set is {}'.format(round(RMSE_train_2,2)))\n",
    "print('RMSE for test set is {}'.format(round(RMSE_test_2,2)))\n",
    "print('MSE for train set is {}'.format(round(MSE_train_2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score for Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_2 = RF.score(X2_train, y2_train)\n",
    "test_score_2 = RF.score(X2_test, y2_test)\n",
    "\n",
    "print(\"Model 2 accuracy score: \")\n",
    "print(\"\")\n",
    "print(\"Train Score = \",round(train_score_2*100,0),\"%\")\n",
    "print(\"Test Score  = \",round(test_score_2*100,0), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Solar Output Values vs Predicted Values for Plant 2 using Random Forest Regresor (This also includes faulty days dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This also includes faulty days dataset\n",
    "plt.scatter(y2_test, y2_pred_test,color=\"r\", label=\"Predicted Output test\")\n",
    "plt.scatter(y2_train, y2_pred_train,color=\"b\", label=\"Predicted Output train\")\n",
    "#plt.scatter(Y_test, DC_POWER, label=\"Measured Output\")\n",
    "#plt.plot(X, Y, \"b.\")\n",
    "plt.legend()\n",
    "plt.title('Actual Solar Output Values vs Predicted Values for Plant 1 using Random Forest')\n",
    "plt.xlabel('Predicted Output')\n",
    "plt.ylabel('Actual Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X2_train)\n",
    "X_test = sc.transform(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model after Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X2_train, y2_train)\n",
    "y3_pred = regressor.predict(X2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy scorefor Model 2 after scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_2 = RF.score(X2_train, y2_train)\n",
    "test_score_2 = RF.score(X2_test, y2_test)\n",
    "\n",
    "print(\"Model 2 accuracy score: \")\n",
    "print(\"\")\n",
    "print(\"Train Score = \",round(train_score_2*100,0),\"%\")\n",
    "print(\"Test Score  = \",round(test_score_2*100,0), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "scores = cross_val_score(lm, X12, y12, cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "scores2 = cross_val_score(svm_reg, X12, y12, cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores2.mean(), scores2.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lm, X1, y1, cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_val_score(RF, X2_train, y2_train, cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeseriessplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def Cross_Validation(model, X, y, n_splits=10):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    scores = []\n",
    "    for train_index, test_index in tscv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        Y_train, Y_test = y.iloc[train_index], y.iloc[test_index] \n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "        predict = model.predict(X_test)\n",
    "\n",
    "        scores.append(model.score(X_test, Y_test))\n",
    "    \n",
    "    return (np.mean(scores), np.std(scores))\n",
    "\n",
    "lm = LinearRegression()\n",
    "mean_score, std = Cross_Validation(lm, X12, y12)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (mean_score, std))\n",
    "\n",
    "lm = LinearRegression()\n",
    "mean_score, std = Cross_Validation(lm, X1, y1)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (mean_score, std))\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "mean_score, std = Cross_Validation(rf, X12, y12)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (mean_score, std))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Tune the parameters of your model. \n",
    "Make predictions regarding the future values for some of your chosen variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing all packages and importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_1=pd.read_csv('./Plant_2_Generation_Data.csv')\n",
    "gen_1.drop('PLANT_ID',1,inplace=True)\n",
    "\n",
    "gen_2=pd.read_csv('./Plant_1_Generation_Data.csv')\n",
    "gen_2.drop('PLANT_ID',1,inplace=True)\n",
    "\n",
    "sens_1= pd.read_csv('./Plant_2_Weather_Sensor_Data.csv')\n",
    "sens_1.drop('PLANT_ID',1,inplace=True)\n",
    "#format datetime\n",
    "gen_1['DATE_TIME']= pd.to_datetime(gen_1['DATE_TIME'],format='%Y-%m-%d %H:%M') #named plant 2 data as gen_1\n",
    "gen_2['DATE_TIME']= pd.to_datetime(gen_2['DATE_TIME'],format='%d-%m-%Y %H:%M') #named plant 1 data as gen_2\n",
    "sens_1['DATE_TIME']= pd.to_datetime(sens_1['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Yield & AC-DC power\n",
    "This plot shows that plant 1 is only outputting barely 10% of expected inverted output. Massive human error involved. Data cannot be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen=gen_1.groupby('DATE_TIME').sum().reset_index() #group all items by the increments, which has several inverters. SUm all the inverter values into one. SO you get one value per time step for each collumn\n",
    "df_gen['time']=df_gen['DATE_TIME'].dt.time #taking the time component from datetime and making a collumn\n",
    "\n",
    "#Setting up plant 2 dataframe\n",
    "df_gen2=gen_2.groupby('DATE_TIME').sum().reset_index()\n",
    "df_gen2['time']=df_gen2['DATE_TIME'].dt.time\n",
    "\n",
    "fig,ax = plt.subplots(ncols=2,nrows=1,dpi=100,figsize=(20,5))\n",
    "\n",
    "# daily yield plot\n",
    "#df_gen.plot(x='DATE_TIME',y='DAILY_YIELD',color='navy',ax=ax[0])\n",
    "\n",
    "\n",
    "# AC & DC power plot\n",
    "df_gen.set_index('time').drop('DATE_TIME',1)[['AC_POWER','DC_POWER']].plot(style='o',ax=ax[0]) #plant 2 plot\n",
    "df_gen2.set_index('time').drop('DATE_TIME',1)[['AC_POWER','DC_POWER']].plot(style='o',ax=ax[1]) #plant 1 plot\n",
    "\n",
    "\n",
    "#ax[0].set_title('Daily yield',)\n",
    "\n",
    "\n",
    "ax[0].set_title('AC power & DC power during day hours for Plant 2')\n",
    "ax[1].set_title('AC power & DC power during day hours for Plant 1')\n",
    "ax[0].set_ylabel('kW',color='navy',fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "pd.options.display.max_rows = 4000 #output text size\n",
    "gen_1[3100:3120] #snapshot of plant 1 to illustrate this dataframe carries several inverters for each time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Illustrate that all inverter values have been added to total across each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen[115:135] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why original DAILY_YIELD and TOTAL_YIELD is wrong\n",
    "\n",
    "Source Data mentions that DAILY_YIELD is a cumulative sum of power generated on that day, till that point in time. Power is a running rate, it cannot be Cumulative. Source Data also mentions TOTAL_YIELD is the total yield for the inverter till that point in time. However, cumulative\n",
    "calculations are not consistent and therefore unusable. \n",
    "\n",
    "A snapshot of 3 days will be shown for both. DAILY_YIELD frequenlty dips, even though it has the correct general shape. This cannot be as it is reasonably a calculated value and is CUMULATIVE. The flat lines of TOTAL_YIELD also indicates to clue that it is not a proper cumulative,\n",
    "especially since DAILY_YIELD is regularly producing output. There is also dips here, which are not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDays = df_gen.loc[(df_gen['DATE_TIME'] > '2020-05-16') & (df_gen['DATE_TIME'] <= \"2020-05-19\")]\n",
    "\n",
    "\n",
    "fig,ax= plt.subplots(ncols=2,dpi=100,figsize=(20,5))\n",
    "testDays['DAILY_YIELD'].plot(ax=ax[0],color='navy') # DAILY_YIELD graph\n",
    "testDays['TOTAL_YIELD'].plot(kind='bar',ax=ax[1],color='navy') #TOTAL_YIELD graph\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "ax[0].set_title('Daily Yield')\n",
    "ax[1].set_title('Total Yield')\n",
    "ax[0].set_ylabel('kW',color='navy',fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "#testDays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating new and correct DAILY_YIELD and TOTAL_YIELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df_gen.copy()\n",
    "new_df = new_df.drop(['DAILY_YIELD','TOTAL_YIELD'], 1) #Dropping DAILY_YIELD & TOTAL_YIELD. UNUSABLE\n",
    "\n",
    "new_df[\"NEW_YIELD\"] = (new_df['AC_POWER'] * 0.25) #Energy generation during this step\n",
    "\n",
    "new_df['date']=new_df['DATE_TIME'].dt.date #taking date component of datetime into a new collumn\n",
    "\n",
    "\n",
    "new_df[\"DAILY_YIELD\"] = new_df.groupby('date').NEW_YIELD.cumsum() \n",
    "new_df[\"TOTAL_YIELD\"] = new_df.NEW_YIELD.cumsum() \n",
    "\n",
    "\n",
    "#testDays = new_df.loc[(new_df['DATE_TIME'] > '2020-05-16') & (new_df['DATE_TIME'] <= \"2020-05-19\")]\n",
    "#new_df = new_df.drop(['DAILY_YIELD','TOTAL_YIELD'], 1)\n",
    "\n",
    "\n",
    "#df_gen=gen_1.groupby('DATE_TIME').sum().reset_index() #group all items by the increments, which has several inverters. SUm all the inverter values into one. SO you get one value per time step for each collumn\n",
    "#df_gen['time']=df_gen['DATE_TIME'].dt.time #taking the time component from datetime and making a collumn\n",
    "\n",
    "new_df[110:130] #snapshot of new dataframe (single step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily and Total Yield Plots\n",
    "Replacing df_gen for easier carrydown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = new_df #replacing df_gen for easier carrydown\n",
    "daily_gen=df_gen.copy()\n",
    "daily_gen['date']=daily_gen['DATE_TIME'].dt.date #taking date component of datetime into a new collumn\n",
    "\n",
    "daily_gen=daily_gen.groupby('date').sum() #summing all the steps in a date so u get one value per date\n",
    "\n",
    "fig,ax= plt.subplots(ncols=2,dpi=100,figsize=(20,5))\n",
    "daily_gen['DAILY_YIELD'].plot(ax=ax[0],color='navy')\n",
    "daily_gen['TOTAL_YIELD'].plot(kind='bar',ax=ax[1],color='navy')\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "ax[0].set_title('Daily Yield')\n",
    "ax[1].set_title('Total Yield')\n",
    "ax[0].set_ylabel('kW',color='navy',fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "daily_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Forecast\n",
    "## Can we predict the power generation for next couple of days? \n",
    "\n",
    "Tune auto_arima function, a SEASONAL ARIMA(p,d,q) + (P,D,Q,m) model,on the last 4 days(384 observations) to see if our model can capture the last generation trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import DateOffset\n",
    "! pip install pmdarima\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New fixed gen_1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gen1=gen_1.copy()\n",
    "new_gen1 = new_gen1.drop(['DAILY_YIELD','TOTAL_YIELD'], 1) #Dropping DAILY_YIELD & TOTAL_YIELD. UNUSABLE\n",
    "\n",
    "new_gen1[\"NEW_YIELD\"] = (new_gen1['AC_POWER'] * 0.25) #Energy generation during this step\n",
    "\n",
    "new_gen1['date']=new_gen1['DATE_TIME'].dt.date #taking date component of datetime into a new collumn\n",
    "\n",
    "\n",
    "new_gen1[\"DAILY_YIELD\"] = new_gen1.groupby(['date', 'SOURCE_KEY']).NEW_YIELD.cumsum() \n",
    "new_gen1[\"TOTAL_YIELD\"] = new_gen1.NEW_YIELD.cumsum() \n",
    "\n",
    "new_gen1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen=new_gen1.copy()\n",
    "pred_gen=pred_gen.groupby('DATE_TIME').sum()\n",
    "pred_gen=pred_gen['DAILY_YIELD'][-288:].reset_index()\n",
    "pred_gen.set_index('DATE_TIME',inplace=True)\n",
    "pred_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Testing for Stationarity\n",
    "\n",
    "\n",
    "* A small p-value (typically ≤ 0.05) indicates strong evidence against the null hypothesis, so you reject the null hypothesis.\n",
    "\n",
    "* A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(pred_gen['DAILY_YIELD'])\n",
    "print('Augmented Dickey-Fuller Test:')\n",
    "labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    "\n",
    "for value,label in zip(result,labels):\n",
    "    print(label+' : '+str(value) )\n",
    "    \n",
    "if result[1] <= 0.05:\n",
    "    print(\"strong evidence against the null hypothesis, reject the null hypothesis. Data has no unit root and is stationary\")\n",
    "else:\n",
    "    print(\"weak evidence against null hypothesis, time series has a unit root, indicating it is non-stationary \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can conclude that the data is non-stationary. Hence, we would need to use the “Integrated (I)” concept, denoted by value ‘d’ in time series to make the data stationary while building the Auto ARIMA model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split into train and test datasets to build the model on the training dataset and forecast using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pred_gen[:192]\n",
    "test=pred_gen[-96:]\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(train,label='Train',color='navy')\n",
    "plt.plot(test,label='Test',color='darkorange')\n",
    "plt.title('Last 4 days of daily yield',fontsize=17)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Tune with the auto_arima function:\n",
    "\n",
    "\n",
    "\n",
    "`P` is  The order of the seasonal component for the auto-regressive (AR) model.\n",
    "\n",
    "`D` is The integration order of the seasonal process.\n",
    "\n",
    "`Q` is The order of the seasonal component of the moving average (MA) model.\n",
    "P and Q and be estimated similarly to p and q via auto_arima, and D can be estimated via a Canova-Hansen test, however m generally requires subject matter knowledge of the data.\n",
    "\n",
    "Since we know that our observations are recorded at 15 minute intervals, (so for each day we have 96 observations) we can choose `m` parameter equal to 96 to capture daily trend.\n",
    "To speed up the parameters search, I fixed a max order of 1 for P,D,Q paramaters in the seasonal component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model = auto_arima(train,\n",
    "                         start_p=0,d=1,start_q=0,\n",
    "                         max_p=4,max_d=4,max_q=4,\n",
    "                         start_P=0,D=1,start_Q=0,\n",
    "                         max_P=1,max_D=1,max_Q=1,m=96,\n",
    "                         seasonal=True,\n",
    "                         error_action='warn',trace=True,\n",
    "                         supress_warning=True,stepwise=True,\n",
    "                         random_state=20,n_fits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Use the trained model which was built earlier to forecast daily yields\n",
    "\n",
    "We use the trained model to forecast the last 96 observations of the test data, 17th June daily yield,  and then we will forecast daily yield for 18th and 19th June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates = [test.index[-1] + DateOffset(minutes=x) for x in range(0,2910,15) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=pd.DataFrame(arima_model.predict(n_periods=96),index=test.index)\n",
    "prediction.columns=['predicted_yield']\n",
    "\n",
    "fig,ax= plt.subplots(ncols=2,nrows=1,dpi=100,figsize=(17,5))\n",
    "ax[0].plot(train,label='Train',color='navy')\n",
    "ax[0].plot(test,label='Test',color='darkorange')\n",
    "ax[0].plot(prediction,label='Prediction',color='green')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Forecast on test set',size=17)\n",
    "ax[0].set_ylabel('kW',color='navy',fontsize=17)\n",
    "\n",
    "\n",
    "f_prediction=pd.DataFrame(arima_model.predict(n_periods=194),index=future_dates)\n",
    "f_prediction.columns=['predicted_yield']\n",
    "ax[1].plot(pred_gen,label='Original data',color='navy')\n",
    "ax[1].plot(f_prediction,label='18th & 19th June',color='green')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Next days forecast',size=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate your model based on different metrics. \n",
    "\n",
    " - R2, \n",
    " - MSE,\n",
    " - RSME,\n",
    " - Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff8b008da7a31bb59aac835c10783dcbad21c495f5d56ff135638213bd8f53bc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
