{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy import stats\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"Solar_Power\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "plant_1_gen = pd.read_csv(\"Plant_1_Generation_data.csv\")\n",
    "plant_2_gen = pd.read_csv(\"Plant_2_Generation_data.csv\")\n",
    "plant_1_wea = pd.read_csv(\"Plant_1_Weather_Sensor_data.csv\")\n",
    "plant_2_wea = pd.read_csv(\"Plant_2_Weather_Sensor_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "our dataset consist of 4 files 2 for each plant\n",
    "- power generation data\n",
    "- weather sensor data\n",
    "\n",
    "### The power generations data consists of 7 fields:\n",
    "| DATE_TIME | PLANT_ID | SOURCE_KEY | DC_POWER | AC_POWER | DAILY_YIELD | TOTAL_YIELD |\n",
    "| --------- | -------- | ---------- | -------- | -------- | ----------- | ----------- |\n",
    "| Date and time for each observation (%d-%m-%Y %H:%M). Observations recorded at 15 minute intervals. | Plant ID - this will be common for the entire file. | Source key in this file stands for the inverter id. | Amount of DC power generated by the inverter (source_key) in this 15 minute interval. Units - kW. | Amount of AC power generated by the inverter (source_key) in this 15 minute interval. Units - kW. | Daily yield is a cumulative sum of power generated on that day till that point in time. | This is the total yield for the inverter till that point in time. |\n",
    "\n",
    "### The weather data consists of 6 fields:\n",
    "| DATE_TIME | PLANT_ID | SOURCE_KEY | AMBIENT_TEMPERATURE | MODULE_TEMPERATURE | IRRADIATION |\n",
    "| --------- | -------- | ---------- | -------- | -------- | ----------- |\n",
    "| Date and time for each observation (%d-%m-%Y %H:%M). Observations recorded at 15 minute intervals. | Plant ID - this will be common for the entire file. | Stands for the sensor panel id. This will be common for the entire file because there's only one sensor panel for the plant. | This is the ambient temperature at the plant. | There's a module (solar panel) attached to the sensor panel. This is the temperature reading for that module. | Amount of irradiation for the 15 minute interval. Solar irradiation is the quantity that measures the energy per unit area of ​​incident solar radiation on a surface - the power received during a time (J/m2 or Wh/m2 )  |\n",
    "\n",
    "Data is gathered every 15 minutes for 34 days.\n",
    "\n",
    "Expecting 3264 samples per sampling point:\n",
    "\n",
    "24 hours x 4 times per hour x 34 days = 3264 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check columns for missing values\n",
    "### plant 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'SOURCE_KEY' is both an index level and a column label, which is ambiguous.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2244/3818772751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplant1_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplant_1_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SOURCE_KEY\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"DATE_TIME\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplant_1_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mplant_1_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SOURCE_KEY\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"bvBOhCH3iADSZry\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mplant_1_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"SOURCE_KEY\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplant_1_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplant_1_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SOURCE_KEY\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplant_1_gen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.env\\.dat540_group_11\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7624\u001b[0m         \u001b[1;31m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7625\u001b[0m         \u001b[1;31m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7626\u001b[1;33m         return DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   7627\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7628\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.env\\.dat540_group_11\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    886\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m    889\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.env\\.dat540_group_11\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    848\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\.env\\.dat540_group_11\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_check_label_or_level_ambiguity\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1731\u001b[0m                 \u001b[1;34mf\"{label_article} {label_type} label, which is ambiguous.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m             )\n\u001b[1;32m-> 1733\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1735\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'SOURCE_KEY' is both an index level and a column label, which is ambiguous."
     ]
    }
   ],
   "source": [
    "missing1 = plant_1_gen.copy()\n",
    "\n",
    "\n",
    "= plant_1_gen.groupby(\"SOURCE_KEY\")[\"DATE_TIME\"].count()\n",
    "plant_1_gen[plant_1_gen[\"SOURCE_KEY\"]==\"bvBOhCH3iADSZry\"]\n",
    "if plant_1_gen.index.name != \"SOURCE_KEY\":\n",
    "    plant_1_gen.set_index(plant_1_gen[\"SOURCE_KEY\"],inplace=True)\n",
    "plant_1_gen\n",
    "# print(plant1_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE_TIME              0\n",
      "PLANT_ID               0\n",
      "SOURCE_KEY             0\n",
      "AMBIENT_TEMPERATURE    0\n",
      "MODULE_TEMPERATURE     0\n",
      "IRRADIATION            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "plant1_wea = plant_1_wea.isnull().sum()\n",
    "print(plant1_wea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plant 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE_TIME      0\n",
      "PLANT_ID       0\n",
      "SOURCE_KEY     0\n",
      "DC_POWER       0\n",
      "AC_POWER       0\n",
      "DAILY_YIELD    0\n",
      "TOTAL_YIELD    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plant2_info = plant_2_gen.isnull().sum()\n",
    "print(plant2_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE_TIME              0\n",
      "PLANT_ID               0\n",
      "SOURCE_KEY             0\n",
      "AMBIENT_TEMPERATURE    0\n",
      "MODULE_TEMPERATURE     0\n",
      "IRRADIATION            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "plant2_wea = plant_2_wea.isnull().sum()\n",
    "print(plant2_wea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many sensors are at each plant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plant 1 has 22 sensors\n",
      "Plant 2 has 22 sensors\n"
     ]
    }
   ],
   "source": [
    "print(\"Plant 1 has\",plant_1_gen['SOURCE_KEY'].nunique(),\"sensors\")\n",
    "print(\"Plant 2 has\",plant_2_gen['SOURCE_KEY'].nunique(),\"sensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do each of the sensors have continues time series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE_TIME\n",
       "2020-01-06 00:00:00    0.0\n",
       "2020-01-06 00:15:00    0.0\n",
       "2020-01-06 00:30:00    0.0\n",
       "2020-01-06 00:45:00    0.0\n",
       "2020-01-06 01:00:00    0.0\n",
       "                      ... \n",
       "2020-12-06 22:45:00    0.0\n",
       "2020-12-06 23:00:00    0.0\n",
       "2020-12-06 23:15:00    0.0\n",
       "2020-12-06 23:30:00    0.0\n",
       "2020-12-06 23:45:00    0.0\n",
       "Freq: 15T, Name: AC_POWER, Length: 32256, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plant_1_gen[\"DATE_TIME\"] = pd.to_datetime(plant_1_gen[\"DATE_TIME\"])\n",
    "plant_1_gen[\"Human_key\"] = plant_1_gen[\"SOURCE_KEY\"].map({val: f\"S{i+1:02d}\" for i, val in enumerate(plant_1_gen[\"SOURCE_KEY\"].unique())})\n",
    "plant_1_sensor_1 = plant_1_gen[(plant_1_gen[\"Human_key\"] == \"S01\")]\n",
    "plant_1_sensor_1.set_index(pd.DatetimeIndex(plant_1_sensor_1[\"DATE_TIME\"]),inplace=True)\n",
    "plant_1_sensor_1[\"AC_POWER\"].resample('15 min').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for 34 days and continuous dates\n",
    "# TODO : refine for each sensor\n",
    "plant_1_gen[\"DATE_TIME\"] = pd.to_datetime(plant_1_gen[\"DATE_TIME\"])\n",
    "plant_1_gen[\"DATE\"] = plant_1_gen[\"DATE_TIME\"].dt.date\n",
    "# fig, axs = plt.subplots(nrows=11, ncols=2, figsize=(15,12))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "# fig.suptitle(\"date\", fontsize = 18, y=0.95)\n",
    "# plt.show()\n",
    "for title, group in plant_1_gen[[\"SOURCE_KEY\",\"DATE_TIME\",\"AC_POWER\"]].groupby(plant_1_gen[\"DATE_TIME\"].dt.date):\n",
    "    for title2, group2 in group[[\"SOURCE_KEY\",\"DATE_TIME\",\"AC_POWER\"]].groupby(\"SOURCE_KEY\"):\n",
    "        group2.plot(x=\"DATE_TIME\",y=\"AC_POWER\",title=f\"{title}-{title2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverterids\n",
    "#Some inverters have more data points then the others\n",
    "print(\"Plant 1 statistics \\n\", plant_1_gen.SOURCE_KEY.value_counts())\n",
    "print(\"Plant 2 statistics \\n\", plant_2_gen.SOURCE_KEY.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plant 1 weather data\n",
    "plant_1_wea['DATE_TIME'] = pd.to_datetime(plant_1_wea['DATE_TIME']) \n",
    "plant_1_wea['TIME'] = plant_1_wea['DATE_TIME'].dt.time \n",
    "#convert datetime column to just date\n",
    "plant_1_wea['DATE'] = pd.to_datetime(plant_1_wea['DATE_TIME'].dt.date)\n",
    "print(plant_1_wea['DATE'])\n",
    "\n",
    "#Plant 2 weather data\n",
    "plant_2_wea['DATE_TIME'] = pd.to_datetime(plant_2_wea['DATE_TIME']) \n",
    "plant_2_wea['TIME'] = plant_2_wea['DATE_TIME'].dt.time \n",
    "#convert datetime column to just date\n",
    "plant_2_wea['DATE'] = pd.to_datetime(plant_2_wea['DATE_TIME'].dt.date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of weather dataset for both the plants:\n",
    "Observations:\n",
    "1. The mean solar irradiation values for both plants are similar.\n",
    "2. The mean module temperature of Plant 1 is  lower than Plant 2 most of the time.\n",
    "3. The mean ambient temperature of Plant 1 is much lower than Plant 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing both plants\n",
    "# Daily Irradiation\n",
    "ambient_compare = sns.lineplot(x='DATE', y='IRRADIATION', data=plant_1_wea, err_style='band', label='Plant 1')\n",
    "sns.lineplot(x='DATE', y='IRRADIATION', data=plant_2_wea, err_style='band', label='Plant 2', ax=ambient_compare)\n",
    "plt.ylabel('Irradiation')\n",
    "plt.xlabel('Date')\n",
    "plt.title('Daily Solar Irradiation for Both Plants')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Daily Module Temperature\n",
    "modtemp_compare = sns.lineplot(x='DATE', y='MODULE_TEMPERATURE', data=plant_1_wea, err_style='band', label='Plant 1')\n",
    "sns.lineplot(x='DATE', y='MODULE_TEMPERATURE', data=plant_2_wea, err_style='band', label='Plant 2', ax=modtemp_compare)\n",
    "plt.ylabel('Module Temperature')\n",
    "plt.xlabel('Date')\n",
    "plt.title('Daily Module Temperature for Both Plants')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Daily Ambient Temperature\n",
    "ambtemp_compare = sns.lineplot(x='DATE', y='AMBIENT_TEMPERATURE', data=plant_1_wea, err_style='band', label='Plant 1')\n",
    "sns.lineplot(x='DATE', y='AMBIENT_TEMPERATURE', data=plant_2_wea, err_style='band', label='Plant 2', ax=ambtemp_compare)\n",
    "plt.ylabel('Ambient Temperature')\n",
    "plt.xlabel('Date')\n",
    "plt.title('Daily Ambient Temperature for Both Plants')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of solar Irradiation for both plants are similar\n",
    "mean_irradiationplant1 = plant_1_wea['IRRADIATION'].mean()\n",
    "print('Mean of solar irradition from Plant1', mean_irradiationplant1)\n",
    "mean_irradiationplant2 =  plant_2_wea['IRRADIATION'].mean()\n",
    "print('Mean of solar irradition from Plant2', mean_irradiationplant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of Module Temperature for both plants (Plant 1 is lower then Plant 2)\n",
    "mean_moduletempplant1 = plant_1_wea['MODULE_TEMPERATURE'].mean()\n",
    "print('Mean of Module Temperature from Plant1', mean_moduletempplant1)\n",
    "mean_moduletempplant2 =  plant_2_wea['MODULE_TEMPERATURE'].mean()\n",
    "print('Mean of Module Temperature from Plant2', mean_moduletempplant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of Ambient Temperature for both plants (Plant 1 is lower then Plant 2)\n",
    "mean_ambienttempplant1 = plant_1_wea['AMBIENT_TEMPERATURE'].mean()\n",
    "print('Mean of Module Temperature from Plant1', mean_ambienttempplant1)\n",
    "mean_ambienttempplant2 =  plant_2_wea['AMBIENT_TEMPERATURE'].mean()\n",
    "print('Mean of Module Temperature from Plant2', mean_ambienttempplant2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unwanted columns. \n",
    "df_weather1 = plant_1_wea.drop(['PLANT_ID', 'SOURCE_KEY'], axis=1)\n",
    "df_plant1 = plant_1_gen.drop(['PLANT_ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatedattime\n",
    "df_plant1['DATE_TIME']= pd.to_datetime(df_plant1['DATE_TIME'],format='%d-%m-%Y %H:%M')\n",
    "df_weather1['DATE_TIME']= pd.to_datetime(df_weather1['DATE_TIME'],format='%Y-%m-%d %H:%M:%S')\n",
    "df_plant1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the dataset\n",
    "df_plant_weather1 = df_plant1.merge(df_weather1, left_on='DATE_TIME', right_on='DATE_TIME')\n",
    "df_plant_weather1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######Data Correlation Analysis########\n",
    "\n",
    "Observations:\n",
    "1. High correlation between DC Power and AC power generation\n",
    "2. High correlation between DC Power and IRRADIATION\n",
    "3. Strong correlation between DC Power, AC Power and Module Temperature and Ambient Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_plant_weather1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"DC_POWER\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.tools.plotting import scatter_matrix # For older versions of Pandas\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"Data_analysis\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "\n",
    "attributes = [\"DC_POWER\", \"AC_POWER\", \"IRRADIATION\",\n",
    "              \"MODULE_TEMPERATURE\",\"AMBIENT_TEMPERATURE\"]\n",
    "scatter_matrix(df_plant_weather1[attributes], figsize=(20, 12))\n",
    "save_fig(\"scatter_matrix_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of DC power generated from each Source Keys.\n",
    "1. The DC power generation plot shows multiple occasion where power generated was zero during daytime.\n",
    "2. Distribution plot of solar irradiation exhibits that the solar radiation never dropped to a lower value at day time. \n",
    "3. Analysis shows some inverters received no DC power even through there was enough sunlight\n",
    "4. It could be concluded that the DC power generated and solar irradiation has a linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DC power generated from each source keys\n",
    "sources=df_plant_weather1.copy()\n",
    "sources['time']=sources['DATE_TIME'].dt.time\n",
    "sources.set_index('time').groupby('SOURCE_KEY')['DC_POWER'].plot(style='o',legend=True,figsize=(20,10))\n",
    "plt.title('DC Power generated for all interverters(source_keys)',size=17)\n",
    "plt.ylabel('DC POWER ( kW )',color='navy',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solar IRRADIATION generated for days\n",
    "sources=df_plant_weather1.copy()\n",
    "sources['time']=sources['DATE_TIME'].dt.time\n",
    "sources['date']=sources['DATE_TIME'].dt.date\n",
    "sources.set_index('time').groupby('date')['IRRADIATION'].plot(style='g',legend=True,figsize=(20,10))\n",
    "plt.title('Distribution of IRRADIATION during daytime',size=17)\n",
    "plt.ylabel('IRRADIATION',color='navy',fontsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "fig_irr = sns.scatterplot(data=df_plant_weather1, x=\"IRRADIATION\", y=\"DC_POWER\", hue=\"SOURCE_KEY\", palette=\"tab20\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dagens dato = \n",
    "gårsdagens = dagens - 1 dag\n",
    "\n",
    "ac_predict = df.apply( func (source_key == source_key) and (date === date -1) null\n",
    "\n",
    "fill_na(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sample(df,min):\n",
    "    x = df.copy()\n",
    "    x.drop(\"SOURCE_KEY\", axis = 1)\n",
    "    x.set_index(\"DATE_TIME\", inplace = True)\n",
    "    x.resample(str(min) + \" min\").mean()\n",
    "    return  x.fillna(0)\n",
    "\n",
    "#print value at 20th may\n",
    "def show15may(df):\n",
    "    start_time =pd.to_datetime('15/5/2020')\n",
    "    end_time =pd.to_datetime('20/5/2020')    \n",
    "\n",
    "dagens Dat\n",
    "\n",
    "persistant = df[\"AC_POWER\" DATE_TIME == td.datediff ('d',-1)]\n",
    "\n",
    "df15 = make_sample(df_plant_weather1, 15)\n",
    "show15may(df15)\n",
    "df30 = make_sample(df_plant_weather1, 30)\n",
    "show15may(df30)\n",
    "df60 = make_sample(df_plant_weather1, 60)\n",
    "show15may(df60)\n",
    "df2h = make_sample(df_plant_weather1, 120)\n",
    "show15may(df2h)\n",
    "df4h = make_sample(df_plant_weather1, 240)\n",
    "show15may(df4h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_null_ac(df):\n",
    "    print(df[df[\"AC_POWER\"].isnull()].sum())\n",
    "\n",
    "show_null_ac(df15)\n",
    "show_null_ac(df30) \n",
    "show_null_ac(df60) \n",
    "show_null_ac(df2h)    \n",
    "show_null_ac(df4h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X1=df_plant_weather1[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE']] # Features \n",
    "y1=df_plant_weather1['DC_POWER'] # independent var / predictor\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=1)\n",
    "\n",
    "print(\"Shape of each Dataset : \")\n",
    "print(\"X Train Shape = \",X1_train.shape)\n",
    "print(\"Y Train Shape = \",y1_train.shape)\n",
    "print(\"X Test Shape  = \",X1_test.shape)\n",
    "print(\"Y Test Shape  = \",y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_pct(score):\n",
    "    return round(score*100,0)\n",
    "\n",
    "def linear_pipeline(df):\n",
    "    lm = LinearRegression()\n",
    "    a = df[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE']] # Features\n",
    "    b = df['DC_POWER'] # Target\n",
    "    a_train, a_test, b_train, b_test = train_test_split(a, b, test_size=0.20, shuffle=False)\n",
    "    lm.fit(a_train, b_train)\n",
    "    training_prediction = lm.predict(a_train)\n",
    "    testing_prediction = lm.predict(a_test)\n",
    "    train_MAE = metrics.mean_absolute_error(b_train, training_prediction)\n",
    "    train_MSE = metrics.mean_squared_error(b_train, training_prediction)\n",
    "    train_RMSE = np.sqrt(metrics.mean_squared_error(b_train, training_prediction))\n",
    "    test_MAE = metrics.mean_absolute_error(b_test, testing_prediction)\n",
    "    test_MSE = metrics.mean_squared_error(b_test, testing_prediction)\n",
    "    test_RMSE = np.sqrt(metrics.mean_squared_error(b_test, testing_prediction))\n",
    "    train_acc_pct = conv_pct(lm.score(a_train, b_train))\n",
    "    test_acc_pct = conv_pct(lm.score(a_test, b_test))\n",
    "    return [training_prediction,testing_prediction]\n",
    "\n",
    "linear_result15 = linear_pipeline(df15)\n",
    "linear_result30 = linear_pipeline(df30)\n",
    "linear_result60 = linear_pipeline(df60)\n",
    "linear_result2h = linear_pipeline(df2h)\n",
    "\n",
    "\n",
    "print(linear_pipeline(df15))\n",
    "print(linear_pipeline(df30))\n",
    "print(linear_pipeline(df60))\n",
    "print(linear_pipeline(df2h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #fit on training data\n",
    "lm.fit(X1_train, y1_train)\n",
    "lm.intercept_, lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Plant 1 linear regression cofficients are:', X.columns, lm.coef_ )\n",
    "print('Plant 1 intercept', lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction from model\n",
    "Prediction_plant1 = lm.predict(X1_test)\n",
    "Prediction_plant1\n",
    "Y1_pred_train = lm.predict(X1_train)\n",
    "Y1_pred_test = lm.predict(X1_test)\n",
    "\n",
    "print ('Prediction Train dataset', Y1_pred_train)\n",
    "print ('Prediction Train dataset', Y1_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This also includes faulty days dataset\n",
    "plt.scatter(y1_test, Y1_pred_test, color=\"b\", label=\"Predicted Output\")\n",
    "#plt.scatter(Y_test, DC_POWER, label=\"Measured Output\")\n",
    "#plt.plot(X, Y, \"b.\")\n",
    "plt.legend()\n",
    "plt.title('Actual Solar Output Values vs Predicted Values for Plant 1')\n",
    "plt.xlabel('Predicted Output')\n",
    "plt.ylabel('Actual Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# PLANT 1\n",
    "MAE1 = metrics.mean_absolute_error(y1_test, Y1_pred_test)\n",
    "MSE1 = metrics.mean_squared_error(y1_test, Y1_pred_test)\n",
    "RMSE1 = np.sqrt(metrics.mean_squared_error(y1_test, Y1_pred_test))\n",
    "print('Metrics for Plant 1 Linear Model')\n",
    "print('MAE: ', MAE1)\n",
    "print('MSE: ',MSE1)\n",
    "print('RMSE: ', RMSE1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Evaluation for Linear Regression Model 1 using RMSE\")\n",
    "print(\"\")\n",
    "RMSE_train_1 = np.sqrt( metrics.mean_squared_error(y1_train, Y1_pred_train))\n",
    "RMSE_test_1 = np.sqrt(metrics.mean_squared_error(y1_test, Y1_pred_test))\n",
    "print('RMSE for training set = {}'.format(round(RMSE_train_1,2)))\n",
    "print('RMSE for test set = {}'.format(round(RMSE_test_1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## acuracy score\n",
    "train_score_1 = lm.score(X1_train, y1_train)\n",
    "test_score_1 = lm.score(X1_test, y1_test)\n",
    "\n",
    "print(\"Model 1 accuracy score: \")\n",
    "print(\"\")\n",
    "print(\"Train Score = \",round(train_score_1*100,0),\"%\")\n",
    "print(\"Test Score  = \",round(test_score_1*100,0), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select columns that will be used to create train and test dataset\n",
    "model_2 = df_plant_weather1\n",
    "model_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create list using feature columns\n",
    "#model_2_features = model_2['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']\n",
    "\n",
    "# use above list to select subset of original dataframe\n",
    "#X2 = model_2[model_2_features]\n",
    "#y3 = model_2[\"DC_POWER\"] # dependent variable / output\n",
    "\n",
    "X2 = model_2[['AMBIENT_TEMPERATURE', 'MODULE_TEMPERATURE', 'IRRADIATION']] # Features\n",
    "y2 = model_2['DC_POWER'] # Target\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test=train_test_split(X2, y2, test_size=0.20, random_state=1) \n",
    "\n",
    "print(\"Shape of each New Dataset : \")\n",
    "print(\"X Train Shape = \",X2_train.shape)\n",
    "print(\"Y Train Shape = \",y2_train.shape)\n",
    "print(\"X Test Shape  = \",X2_test.shape)\n",
    "print(\"Y Test Shape  = \",y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RF = RandomForestRegressor()\n",
    "RF.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred_train = RF.predict(X2_train)\n",
    "y2_pred_test = RF.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Evaluation for Random Forest Model 2 using RMSE\")\n",
    "\n",
    "RMSE_train_2 = np.sqrt( metrics.mean_squared_error(y2_train, y2_pred_train))\n",
    "RMSE_test_2 = np.sqrt(metrics.mean_squared_error(y2_test, y2_pred_test))\n",
    "MSE_train_2 = ( metrics.mean_squared_error(y2_train, y2_pred_train))\n",
    "print('RMSE for training set is {}'.format(round(RMSE_train_2,2)))\n",
    "print('RMSE for test set is {}'.format(round(RMSE_test_2,2)))\n",
    "print('MSE for train set is {}'.format(round(MSE_train_2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## acuracy scorefor Model 2\n",
    "## acuracy score\n",
    "train_score_2 = RF.score(X2_train, y2_train)\n",
    "test_score_2 = RF.score(X2_test, y2_test)\n",
    "\n",
    "print(\"Model 2 accuracy score: \")\n",
    "print(\"\")\n",
    "print(\"Train Score = \",round(train_score_2*100,0),\"%\")\n",
    "print(\"Test Score  = \",round(test_score_2*100,0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This also includes faulty days dataset\n",
    "plt.scatter(y2_test, y2_pred_test,color=\"r\", label=\"Predicted Output test\")\n",
    "plt.scatter(y2_train, y2_pred_train,color=\"b\", label=\"Predicted Output train\")\n",
    "#plt.scatter(Y_test, DC_POWER, label=\"Measured Output\")\n",
    "#plt.plot(X, Y, \"b.\")\n",
    "plt.legend()\n",
    "plt.title('Actual Solar Output Values vs Predicted Values for Plant 1 using Random Forest')\n",
    "plt.xlabel('Predicted Output')\n",
    "plt.ylabel('Actual Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X2_train)\n",
    "X_test = sc.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X2_train, y2_train)\n",
    "y3_pred = regressor.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv_2020 = df_plant_weather1\n",
    "conv_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = conv_2020['DATE_TIME']\n",
    "y = conv_2020['DC_POWER']\n",
    "slope, intercept, r, p, std_err = stats.linregress(X, y)\n",
    "\n",
    "def modelPrediction(x):\n",
    "  return slope * x + intercept\n",
    "\n",
    "label = 'Model Prediction for conventional avocado in 2020 is = '\n",
    "\n",
    "model = list(map(modelPrediction, X)) # scipy\n",
    "\n",
    "x_pred = 2020\n",
    "y_pred = modelPrediction(x_pred)\n",
    "print(label)\n",
    "\n",
    "ap_conv_2020 = round(y_pred, 2)\n",
    "print('$ {}'.format(ap_conv_2020))\n",
    "print(\"\")\n",
    "\n",
    "plt.scatter(X, y) # Scatter Plot\n",
    "plt.plot(X, model, color='red')\n",
    "plt.ylim(ymin=0) # starts at zero\n",
    "plt.legend(['Model Prediction', 'Conventional Avocado Prices (2015-2019)'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1b01ef8c97daba961190247903c8d61e5dc4a844265e5e156c14a54bd1266b5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
